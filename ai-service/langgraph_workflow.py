"""
LangGraph Workflow for Spring Boot Integration
Minimal workflow for complete_analysis flow: RAG â†’ Learning â†’ Jobs â†’ Email
"""

from langgraph.graph import StateGraph, END
from typing import List, Dict, Optional
from typing_extensions import TypedDict
from langchain.agents import create_agent
from langchain.tools import tool
from langchain_deepseek import ChatDeepSeek
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv

# Import RAG modules
from rag.rag_step_1_loading import load_documents_from_folder
from rag.rag_step_2_chunking import chunk_documents
from rag.rag_step_3_embeddings import embed_texts
from rag.rag_step_4_vector_db import get_db_collection, should_reindex_documents, save_index_metadata
from rag.rag_step_6_similarity import retrieve_relevant_chunks
from rag.rag_step_7_prompt import prepare_prompt
from rag.rag_step_8_call_llm import generate_answer

import os
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import json
import requests
import time

load_dotenv()

# ============================================================================
# LLM CONFIGURATION
# ============================================================================

def get_deepseek():
    """
    Returns ChatDeepSeek model for LLM operations.
    """
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    url = os.getenv("DEEPSEEK_API_BASE", "https://api.deepseek.com")

    llm_model = ChatDeepSeek(
        model="deepseek-chat",
        max_tokens=2000,
        timeout=120,  # Increased timeout
        max_retries=3,  # Add retries
        api_key=deepseek_key,
        base_url=url
    )
    return llm_model

# Main LLM instance
llm = get_deepseek()

# ============================================================================
# STATE DEFINITION
# ============================================================================

class AppState(TypedDict):
    """
    State for complete_analysis workflow from Spring Boot.
    """
    query: str  # "complete_analysis"
    code: str  # Personality code from Spring Boot (e.g., "R-I-A")
    student_info: dict  # Student information
    scores: dict  # Metric scores
    
    # Outputs
    rag_output: str | None  # Career recommendations
    api_results: str | None  # Learning path
    job_answer: dict | None  # Job matches
    email_status: str | None  # Email status
    
    # Control
    human_email_decision: str | None
    final_answer: dict | None

# ============================================================================
# TOOLS
# ============================================================================

@tool
def universities_tool(query: str) -> str:
    """
    Fetch comprehensive university and major recommendations based on a query.
    Returns a list of universities in Lebanon and the region with links.
    """
    return """
Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù…Ø¹Ø§Øª Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§:
1. Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù„Ø¨Ù†Ø§Ù†ÙŠØ© (LU): ØªØ¶Ù… ØªØ®ØµØµØ§Øª Ù…ØªÙ†ÙˆØ¹Ø© ÙÙŠ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©ØŒ Ø§Ù„Ø¹Ù„ÙˆÙ…ØŒ ÙˆØ§Ù„Ø­Ù‚ÙˆÙ‚. (https://www.ul.edu.lb)
2. Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© ÙÙŠ Ø¨ÙŠØ±ÙˆØª (AUB): Ø±Ø§Ø¦Ø¯Ø© ÙÙŠ Ø§Ù„Ø·Ø¨ØŒ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©ØŒ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¹Ù…Ø§Ù„. (https://www.aub.edu.lb)
3. Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ø¯ÙŠØ³ ÙŠÙˆØ³Ù (USJ): ØªÙ…ÙŠØ² ÙÙŠ Ø§Ù„Ø·Ø¨ØŒ Ø§Ù„Ø¹Ù„ÙˆÙ… Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©. (https://www.usj.edu.lb)
4. Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù„Ø¨Ù†Ø§Ù†ÙŠØ© Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© (LAU): ØªØ®ØµØµØ§Øª Ù…ØªÙ…ÙŠØ²Ø© ÙÙŠ Ø§Ù„ØµÙŠØ¯Ù„Ø©ØŒ Ø§Ù„ØªØµÙ…ÙŠÙ…ØŒ ÙˆÙ‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¹Ù…Ø§Ø±Ø©. (https://www.lau.edu.lb)
5. Ø¬Ø§Ù…Ø¹Ø© Ø¨ÙŠØ±ÙˆØª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (BAU): ØªØ®ØµØµØ§Øª Ø´Ø§Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ø¹Ù„ÙˆÙ… Ø§Ù„Ø·Ø¨ÙŠØ© ÙˆØ§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©. (https://www.bau.edu.lb)
"""

@tool
def courses_tool(query: str) -> str:
    """
    Fetch online course recommendations from major platforms (Coursera, Udemy, EdX).
    Returns specific courses related to the career path with links.
    """
    return """
Ø¯ÙˆØ±Ø§Øª ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ù…Ù‚ØªØ±Ø­Ø©:
1. Ù…Ø³Ø§Ø±Ø§Øª Google Ø§Ù„Ù…Ù‡Ù†ÙŠØ© (Coursera): ØªØºØ·ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ØŒ ÙˆØ§Ù„Ø¯Ø¹Ù… Ø§Ù„ØªÙ‚Ù†ÙŠ. (https://www.coursera.org/google-career-certificates)
2. Ø¯ÙˆØ±Ø§Øª edX Ø§Ù„ØªØ®ØµØµÙŠØ©: ØªÙ‚Ø¯Ù… Ø´Ù‡Ø§Ø¯Ø§Øª Ù…Ù† Ù‡Ø§Ø±ÙØ§Ø±Ø¯ ÙˆMIT ÙÙŠ ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„Ø¨Ø±Ù…Ø¬Ø©. (https://www.edx.org)
3. Udemy Professional Courses: Ø¯ÙˆØ±Ø§Øª Ø¹Ù…Ù„ÙŠØ© ÙÙŠ Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ø¬Ø±Ø§ÙÙŠÙƒÙŠØŒ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø±Ù‚Ù…ÙŠØŒ ÙˆØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆÙŠØ¨. (https://www.udemy.com)
4. LinkedIn Learning: Ø¯ÙˆØ±Ø§Øª ÙÙŠ Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©ØŒ Ø§Ù„ØªÙˆØ§ØµÙ„ØŒ ÙˆØ§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ© (Soft Skills). (https://www.linkedin.com/learning)
"""

@tool
def send_email_tool(email_data: str) -> str:
    """
    Send email with career guidance.
    Expects JSON: {recipient_email, subject, body}
    """
    print("\nğŸ“§ SEND EMAIL TOOL")
    
    try:
        data = json.loads(email_data)
        recipient_email = data.get("recipient_email")
        subject = data.get("subject")
        body = data.get("body")
        
        # Email config
        sender_email = os.getenv("SENDER_EMAIL")
        sender_password = os.getenv("SENDER_APP_PASSWORD")
        smtp_server = os.getenv("SMTP_SERVER", "smtp.gmail.com")
        smtp_port = int(os.getenv("SMTP_PORT", "587"))
        
        if not sender_email or not sender_password:
            return "Error: Email credentials not configured"
        
        # Create message
        message = MIMEMultipart("alternative")
        message["Subject"] = subject
        message["From"] = sender_email
        message["To"] = recipient_email
        
        # HTML body
        body_html = body.replace('\n', '<br>')
        html_body = f"""
        <html>
            <body style="font-family: Arial, sans-serif; direction: rtl; text-align: right;">
                <div style="max-width: 600px; margin: 0 auto; padding: 20px;">
                    {body_html}
                </div>
            </body>
        </html>
        """
        
        part = MIMEText(html_body, "html", "utf-8")
        message.attach(part)
        
        # Send
        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(sender_email, sender_password)
            server.send_message(message)
        
        return f"âœ… Email sent successfully to {recipient_email}"
        
    except Exception as e:
        return f"Error sending email: {str(e)}"

# ============================================================================
# NODES (Only for Spring Boot complete_analysis flow)
# ============================================================================

def rag_node(state: AppState):
    """
    RAG node with smart caching.
    Retrieves career recommendations based on personality code.
    """
    print("\nğŸ” RAG Node")
    
    # folder_path = "./rag/uploaded_files/"
    folder_path = os.getenv("AI_DOCUMENTS_PATH", "./rag/uploaded_files/")
    my_rag_collection = get_db_collection()
    
    # Smart caching - only reindex if files changed
    needs_reindex, current_files = should_reindex_documents(my_rag_collection, folder_path)
    
    if needs_reindex:
        print("ğŸ”„ Reindexing documents...")
        
        source_list = load_documents_from_folder(folder_path)
        if not source_list:
            return {"rag_output": "Ù„Ø§ ØªØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù‡Ù†ÙŠØ©."}
        
        my_chunks_with_metadata = chunk_documents(source_list)
        if not my_chunks_with_metadata:
            return {"rag_output": "Ù„Ø§ ØªØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù‡Ù†ÙŠØ©."}
        
        ids_list = [f"chunk_{i}" for i in range(len(my_chunks_with_metadata))]
        text_list = [chunk["text"] for chunk in my_chunks_with_metadata]
        metadata_list = [{
            'source': chunk['source'],
            'doc_id': chunk['doc_id'],
            'chunk_id': chunk['chunk_id']
        } for chunk in my_chunks_with_metadata]
        
        vectors_list = embed_texts(text_list)
        if vectors_list is None or len(vectors_list) == 0:
            return {"rag_output": "Ù„Ø§ ØªØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù‡Ù†ÙŠØ©."}
        
        # Clear and upsert
        all_ids = [f"chunk_{i}" for i in range(my_rag_collection.count())]
        if all_ids:
            my_rag_collection.delete(ids=all_ids)
        
        my_rag_collection.upsert(
            ids=ids_list,
            embeddings=vectors_list,
            documents=text_list,
            metadatas=metadata_list
        )
        
        save_index_metadata(current_files)
        print(f"âœ… Indexed {my_rag_collection.count()} chunks")
    else:
        print(f"âœ… Documents unchanged - using existing index")
        print(f"   Indexed chunks: {my_rag_collection.count()}")
    
    # Query RAG
    personality_code = state.get("code", "")
    if not personality_code:
        return {"rag_output": "Ø±Ù…Ø² Ø§Ù„Ø´Ø®ØµÙŠØ© ØºÙŠØ± Ù…ØªÙˆÙØ±."}
    
    try:
        query = f"""Ø±Ù…Ø² Ø§Ù„Ø´Ø®ØµÙŠØ© {personality_code} Ø­Ø³Ø¨ Ù†Ø¸Ø±ÙŠØ© Ù‡ÙˆÙ„Ù†Ø¯:
1. Ø§Ø´Ø±Ø­ Ø³Ù…Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©
2. Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ù‡Ù†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
"""
        
        question_vector = embed_texts([query])
        result = retrieve_relevant_chunks(question_vector, my_rag_collection, 10)
        prompt = prepare_prompt(query, result['documents'][0])
        career_recommendations = generate_answer(prompt, os.getenv("DEEPSEEK_API_KEY"))
        
        print(f"âœ… Generated recommendations for {personality_code}")
        return {"rag_output": career_recommendations}
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return {"rag_output": f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"}


def learn_agent_direct(state: AppState):
    """
    Learning path agent - DIRECT TOOL EXECUTION (No LLM agent).
    This is more reliable and faster than using an agent.
    """
    print("\nğŸ“š Learning Path Agent (Direct Mode)")
    
    code = state.get("code", "")
    
    try:
        # Call tools directly without LLM agent
        universities = universities_tool.invoke(code)
        courses = courses_tool.invoke(code)
        
        # Format response
        api_results = f"""
## ğŸ“š Ø§Ù„Ø®Ø·Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù„Ø±Ù…Ø² Ø§Ù„Ø´Ø®ØµÙŠØ© {code}

### ğŸ“ Ø§Ù„Ø¬Ø§Ù…Ø¹Ø§Øª Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§:
{universities}

### ğŸ’» Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:
{courses}

### ğŸ”— Ù…Ù„Ø§Ø­Ø¸Ø©:
ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ù‡Ø°Ù‡ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø³Ù…Ø§Øª Ø´Ø®ØµÙŠØªÙƒ. ÙŠÙ…ÙƒÙ†Ùƒ Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„ ÙˆØ§Ù„ØªØ³Ø¬ÙŠÙ„.
"""
        
        print("âœ… Learning path generated successfully")
        return {"api_results": api_results}
        
    except Exception as e:
        print(f"âŒ Error in learn_agent_direct: {e}")
        # Fallback response
        return {
            "api_results": f"""
## ğŸ“š Ø§Ù„Ø®Ø·Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù„Ø±Ù…Ø² Ø§Ù„Ø´Ø®ØµÙŠØ© {code}

### ğŸ“ Ø§Ù„Ø¬Ø§Ù…Ø¹Ø§Øª Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§ ÙÙŠ Ù„Ø¨Ù†Ø§Ù†:
1. Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù„Ø¨Ù†Ø§Ù†ÙŠØ© (LU) - https://www.ul.edu.lb
2. Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© ÙÙŠ Ø¨ÙŠØ±ÙˆØª (AUB) - https://www.aub.edu.lb
3. Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ø¯ÙŠØ³ ÙŠÙˆØ³Ù (USJ) - https://www.usj.edu.lb

### ğŸ’» Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:
1. Google Career Certificates - https://www.coursera.org/google-career-certificates
2. edX Professional Programs - https://www.edx.org
3. LinkedIn Learning - https://www.linkedin.com/learning
"""
        }


def learn_agent_with_retry(state: AppState):
    """
    Learning path agent with LLM and retry logic (BACKUP - if direct mode fails).
    """
    print("\nğŸ“š Learning Path Agent (LLM Mode with Retry)")
    
    code = state.get("code", "")
    max_retries = 2
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            # Create agent with minimal prompt
            agent = create_agent(
                model=llm,
                tools=[universities_tool, courses_tool],
                system_prompt=f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø¥Ø±Ø´Ø§Ø¯ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ.

Ù‚Ø¯Ù… Ù„Ø±Ù…Ø² {code}:
1. 3 Ø¬Ø§Ù…Ø¹Ø§Øª Ù…Ø¹ Ø±ÙˆØ§Ø¨Ø·
2. 3 Ø¯ÙˆØ±Ø§Øª Ù…Ø¹ Ø±ÙˆØ§Ø¨Ø·

Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©. ÙƒÙ† Ù…Ø®ØªØµØ±Ø§Ù‹.
"""
            )
            
            result = agent.invoke({"messages": f"ØªÙˆØµÙŠØ§Øª Ù„Ø±Ù…Ø² {code}"})
            api_results = result["messages"][-1].content
            
            print(f"âœ… Learning path generated (attempt {attempt + 1})")
            return {"api_results": api_results}
            
        except Exception as e:
            print(f"âš ï¸  Attempt {attempt + 1}/{max_retries} failed: {str(e)}")
            
            if attempt < max_retries - 1:
                wait_time = retry_delay * (2 ** attempt)
                print(f"   Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
            else:
                print("âŒ All attempts failed, falling back to direct mode")
                return learn_agent_direct(state)


def learn_agent_safe(state: AppState):
    """
    SAFE WRAPPER for learn agent.
    Try direct mode first (fastest), fallback to LLM mode if needed.
    """
    try:
        # Try direct mode first (most reliable)
        return learn_agent_direct(state)
    except Exception as e:
        print(f"âŒ Direct mode failed: {e}")
        print("ğŸ”„ Falling back to LLM mode...")
        try:
            return learn_agent_with_retry(state)
        except Exception as e2:
            print(f"âŒ LLM mode also failed: {e2}")
            # Ultimate fallback - static response
            code = state.get("code", "")
            return {
                "api_results": f"""
## ğŸ“š Ø§Ù„Ø®Ø·Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù„Ø±Ù…Ø² Ø§Ù„Ø´Ø®ØµÙŠØ© {code}

### ğŸ“ Ø§Ù„Ø¬Ø§Ù…Ø¹Ø§Øª Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§:
1. Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù„Ø¨Ù†Ø§Ù†ÙŠØ© (LU) - https://www.ul.edu.lb
2. Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© ÙÙŠ Ø¨ÙŠØ±ÙˆØª (AUB) - https://www.aub.edu.lb
3. Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ø¯ÙŠØ³ ÙŠÙˆØ³Ù (USJ) - https://www.usj.edu.lb

### ğŸ’» Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©:
1. Coursera - https://www.coursera.org
2. edX - https://www.edx.org
3. LinkedIn Learning - https://www.linkedin.com/learning

*Ù…Ù„Ø§Ø­Ø¸Ø©: Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø®ØµØµØ©. Ù‡Ø°Ù‡ Ù‚Ø§Ø¦Ù…Ø© Ø¹Ø§Ù…Ø©.*
"""
            }


def node_fetch_jobs(state: AppState):
    """
    Fetch jobs from API.
    """
    print("\nğŸ’¼ Fetching Jobs")
    
    try:
        url = "https://jobicy.com/api/v2/remote-jobs?count=10&geo=canada&industry=dev"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        r = requests.get(url, headers=headers, timeout=20)
        r.raise_for_status()
        data = r.json()
        return {"job_answer": {"jobs": data.get("jobs", [])[:5]}}
    except Exception as e:
        print(f"âŒ Job fetch failed: {e}")
        return {"job_answer": {"error": str(e), "jobs": []}}


def email_agent(state: AppState):
    """
    Email agent - formats and sends comprehensive email using DeepSeek.
    """
    print("\nğŸ“§ Email Agent")
    
    info = state["student_info"]
    rag = state.get("rag_output", "")
    code = state.get("code", "")
    learning = state.get("api_results", "")
    jobs = state.get("job_answer", {})
    
    recipient_email = info.get("email")
    student_name = info.get("name", "Ø§Ù„Ø·Ø§Ù„Ø¨")
    
    if not recipient_email:
        return {"email_status": "No email provided"}
    
    # Format jobs
    jobs_text = ""
    job_list = jobs.get("jobs", [])
    if job_list:
        jobs_text = "<h3>ğŸ’¼ ÙØ±Øµ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…ØªØ§Ø­Ø©:</h3><ul>"
        for job in job_list[:5]:
            jobs_text += f"<li><strong>{job.get('title', 'N/A')}</strong> - {job.get('company', 'N/A')}</li>"
        jobs_text += "</ul>"
    
    # Minimal system prompt - NO MARKDOWN, HTML ONLY
    system_prompt = f"""
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¥Ø±Ø´Ø§Ø¯ Ù…Ù‡Ù†ÙŠ.

Ø£Ø±Ø³Ù„ Ø¨Ø±ÙŠØ¯ Ù„Ù€ "{student_name}" Ø¹Ù† Ø±Ù…Ø² {code}.

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹:
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Markdown Ø£Ø¨Ø¯Ø§Ù‹ (Ù…Ù…Ù†ÙˆØ¹ ##ØŒ **ØŒ *ØŒ _)
- Ø§Ø³ØªØ®Ø¯Ù… HTML ÙÙ‚Ø·: <h2>, <h3>, <p>, <ul>, <li>, <strong>, <br>
- Ù„Ø§ ØªÙƒØªØ¨ Ø£ÙŠ Ø±Ù…ÙˆØ² Ù…Ø«Ù„ ### Ø£Ùˆ ** Ø£Ùˆ ***

Ø§Ù„Ù…Ø­ØªÙˆÙ‰:
1. Ù…Ù‚Ø¯Ù…Ø© Ø¨Ø³ÙŠØ·Ø©
2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø®ØµÙŠØ©: {rag[:400]}
3. Ø§Ù„Ø¬Ø§Ù…Ø¹Ø§Øª ÙˆØ§Ù„Ø¯ÙˆØ±Ø§Øª: {learning[:400]}
4. Ø§Ù„ÙˆØ¸Ø§Ø¦Ù: {jobs_text if jobs_text else "<p>Ø³ÙŠØªÙ… ØªØ­Ø¯ÙŠØ« ÙØ±Øµ Ø§Ù„Ø¹Ù…Ù„ Ù‚Ø±ÙŠØ¨Ø§Ù‹.</p>"}

Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµØ­ÙŠØ­:
- Ø¹Ù†ÙˆØ§Ù† ÙƒØ¨ÙŠØ±: <h2>Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù‡Ù†Ø§</h2>
- Ø¹Ù†ÙˆØ§Ù† ØµØºÙŠØ±: <h3>Ø¹Ù†ÙˆØ§Ù† ÙØ±Ø¹ÙŠ</h3>
- ÙÙ‚Ø±Ø©: <p>Ø§Ù„Ù†Øµ Ù‡Ù†Ø§</p>
- Ù‚Ø§Ø¦Ù…Ø©: <ul><li>Ø§Ù„Ø¨Ù†Ø¯ Ø§Ù„Ø£ÙˆÙ„</li><li>Ø§Ù„Ø¨Ù†Ø¯ Ø§Ù„Ø«Ø§Ù†ÙŠ</li></ul>
- Ù†Øµ ØºØ§Ù…Ù‚: <strong>Ù†Øµ Ù…Ù‡Ù…</strong>
- Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯: <br>

JSON ÙÙ‚Ø·:
{{
  "recipient_email": "{recipient_email}",
  "subject": "Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„Ùƒ Ø§Ù„Ù…Ù‡Ù†ÙŠ ÙˆØ§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„",
  "body": "...HTML Ù‡Ù†Ø§ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Markdown..."
}}

Ø§Ø³ØªØ¯Ø¹ send_email_tool ÙÙˆØ±Ø§Ù‹.

Ù‡Ø§Ù… Ø¬Ø¯Ø§Ù‹: Ø¥Ø°Ø§ ØªÙ… Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­ØŒ ÙŠØ¬Ø¨ Ø£Ù† ØªØ­ØªÙˆÙŠ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© "SUCCESS" (Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©) Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ù„ØªØ£ÙƒÙŠØ¯Ùƒ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
"""
    
    try:
        # Create agent
        agent = create_agent(
            model=llm,
            tools=[send_email_tool],
            system_prompt=system_prompt
        )
        
        result = agent.invoke({"messages": "Ø£Ø±Ø³Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯"})
        final_message = result["messages"][-1].content
        
        return {"email_status": final_message}
        
    except Exception as e:
        print(f"âŒ Email agent failed: {e}")
        return {"email_status": f"Error: {str(e)}"}


def final_format(state: AppState):
    """
    Format final response for Spring Boot.
    """
    response = {
        "code": state.get('code', ''),
        "rag_output": state.get('rag_output', ''),
        "api_results": state.get('api_results', ''),
        "job_answer": state.get('job_answer', {}),
        "email_status": state.get('email_status', ''),
    }
    return {"final_answer": response}

# ============================================================================
# GRAPH CONSTRUCTION (Minimal for Spring Boot)
# ============================================================================

graph = StateGraph(AppState)

# Add only needed nodes
graph.add_node("rag", rag_node)
graph.add_node("learn", learn_agent_safe)  # Using safe wrapper
graph.add_node("fetch_jobs", node_fetch_jobs)
graph.add_node("email", email_agent)
graph.add_node("final", final_format)

# Set entry point
graph.set_entry_point("rag")

# Simple linear flow for complete_analysis
graph.add_edge("rag", "learn")
graph.add_edge("learn", "fetch_jobs")
graph.add_edge("fetch_jobs", "email")
graph.add_edge("email", "final")
graph.add_edge("final", END)

# Compile
memory = MemorySaver()
app = graph.compile(checkpointer=memory)

print("âœ… LangGraph workflow loaded")
print("   Flow: RAG â†’ Learning â†’ Jobs â†’ Email â†’ Final")
print("   LLM: DeepSeek")
print("   Tools: universities_tool, courses_tool, send_email_tool")
print("   Mode: Direct tool execution (safe & fast)")

